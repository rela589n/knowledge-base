# 2. Data Models and Query Languages

Complex applications are layered. Each layer hides complexity of layer below making it easier to understand the concept as a whole.

The data models embodies how they are going to be used and defines possibilities and limitations of layer above, so it's important to choose correct data model.

## Relational VS Document Models

SQL-databases (relational) are general-purpuse and widely used for diverse purposes.

### Birth of NoSQL

#NoSQL - retroactively interpretead as Not Only SQL.

Designed with desire for:
- greater and easier scalability, especially for high write throughput;
- open-source preferred over commercial db;
- special queries not supported by relational dbs;
- more dynamic.

Relational databases are now used alongside with non-relational datastores. This is called _polyglot persistence_.

### Object relational mismatch

Objects in applications are not of the same structure as database tables. Transition layer is required here to work properly. Such disconnect is called _impedance mismatch_.

In order to save relations we could:
- normalize everything (for each entity separate table);
- store related entities as single column (for example json type) if there's support for it;
- encode related entities and store as string text, but there won't be possibility to query for values inside.

For something simple, json model is the best fit. For example, resume which has positions, educations, contact informations.

The json schema has better locality of data meaning that we don't neet to join any other tables.

For cases when json is more appropriate, relational data will have tree structure. It is not 
so obvious that those multiple tables form single tree, while json makes it clear.

### Many-To-One and Many-To-Many

Some values may be stored directly in table column or extracted to separate table and id of record will be used insted.

The rule of thumb here is to normalize everything which is ever needed to be changed by humans. For instance we can rely on ids because people have no intetion to change it. But they definitely do have intention to change the data which they entered by themselves. If such data duplicated across the records, table needs to be normalized.

Some of NoSQL databases has weak support for joins and sometimes it's up to application to emulate join by means of making multiple db requests. Even if initially database structure is join-free, it may become more complex when new features are needed.

### Are Document Databases Repeating History?

#### The network model

This model was called to solve issues of hierarchical models (json-like) to allow many-to-many relationships. It allowed single node to have not only one parent, but multiple. There were no foreign keys, but rather pointers (like programming pointers) and for fetching data it was necessary to lookup for all those paths.

When multiple access paths lead to same record it was up to developer to keep track of them.


#### The relational model

Relational model just lays out all the data in the open. Compared to network model, it does joins at query time rather than insert time. Relational databases queries hides all low level logic like "access path" - which indices to use, which order to execute query in. This decisions are made automatically by query planner.

In order to modify query execution logic we can just declare new index and query will automatically (no chages to it are necessary) use whichever indexes are most appropriate.


#### Comparison to document databases

Document databases store information hierarchically for one-to-many relations, however when it comes to many-to-one or many-to-many relations, _document reference_ (_foreign key_) is used. And in query time it is _followed up_ (_joined_).

### Relational Versus Document Databases Today

Main arguments of Document-based are: schema flexibility, better performance due to 
data locality and structure may be closer to application structures.

Relational models are better at: joining data, support for many-to-one and many-to-many relationships.

#### Which data model leads to simpler application code?

If data schema has document-like structure then it's probably better to use document model. Relational databases and _shredding_ (normalization of every single piece) can make application unnecessarily complex.

Document models can be used for something simple, which doesn't requre many-to-many relationships. For example, storing events inside document database is completely ok.

For highly interconnected data, document model won't fit, relational will be acceptable, and graph model will be natural.

#### Schema flexibility in Document Models

Usually there is no any schama enforcement in document databases and json fields of relational databases. XML columns may have optional schema validation. 

This means that data has implicit schema. In other words, _schema on read_ - meaning application anyway expect data to have some structure when reading. It's the opposite of _schema on write_, which is used in traditional relational databases, and ensures schema validity.

_Schema on read_ is similar to dynamic languages, whereas _Schema on write_ to static ones. Generally there's no wrong or right solution. The key difference is visible when schema changes are necessary (for instance, split column into two). For static schema we'd create migration, but for dynamic we will have to write additional logic in code to handle specific cases of already existing data.

_Schema on read_ is applicable when collection of data has not the same structure (for example, events in event sourcing system may have way too different structure, and it's impractical to create separate table for every single event class).

#### Convergence of document and relational databases

Today relational databases have support for both json and xml columns (with features like query inside of them and local modifications). From other hand, document databases already added support for joins (something like `$lookup`  aggregation in MongoDB). This way, databases complement each other.

## Query languages for data

SQL is declarative language, which allows database system and query optimizer space to execute query in any way it wants. The query can even be executed in parallel. With imperative approach this would not be possible as it defines exactly how to search result rather than what conditions it should meet (as declarative approach does).

### Declaravite queries on the Web

The good example of declarative approach is HTML and CSS. In HTML we don't provide any logic of how elements should be displayed. In CSS we provide conditions necessary in order for elements to show up this way.

If there were no CSS this would lead to tons of awful imperative javascript code for manipulating styles.

In DB perspective declarative SQL is much better than imperative apis.

### MapReduce Querying

MapReduce is programming model for big data processing across multiple machines. It's feature is ability to inject client code during query execution. The `map` function is given with current database record and must emit `key`  and `value` . Later on those keys and values will be passed to `reduce` function, which has to return single element.

The functions  `map` and `reduce` must be _pure functions_ so that the database can execute them in any order, any number of times, on any server, etc.

This is supported by MongoDB extension.

The problem of usability here comes to that it is usually better to use native features of database storage (`GROUP BY`, or `$group`), as it allows query optimizer get into business making queries more performant compared to MapReduce.

## Graph-like data models

Even though relational databases have minimal support for many to many relations, when there are lots of them, it can barely handle it.  When document databases are completely inappropriate for this, _graph databases_ are best fit.

Graph databases can handle not only homogeneous data like friends graph, but moreover graphs of completely different entities (like people, locations, events and anything else).

Graph models:
- **property graph model** (implemeted by neo4j, titan, infinitegraph);
- **triple-store model** (implemented by datomic, allegrograph);

### Property Graphs

Each **vertex** consists of:
- unique id;
- set of outgoing edges;
- set of incoming edges;
- properties (key-value pairs);

Each **edge** consists of:
- unique id;
- edge tail (vertex where edge starts);
- edge head (vertex where edge ends);
- type of relationship (label);
- properties (key-value pairs).

In relational database this would look like two tables - one for vertices another for edges.

Aspects of this model:
- any **vertex can be connected to any vertex** - they don't have to be of the same type;
- for any given vertex we are able to **traverse graph forward and backward**;
- using different labels for different relationships we can store several kinds of information in single graph, while data model is still clean.

> Graphs are greatly support evolvable as they are really flexible. They support different types of data granularity (for instance, street/city may be specified as address,  or region/department, but as soon as they have common type of ancestor we can compare ancestors (country)))


### Cypher Query Language

[[Cypher]] - declarative query language, for property graphs, created for [[Neo4j]] databases.

Example create query:

```cypher
CREATE
  (NAmerica:Location {name: 'North America', type: 'continent'}),
  (USA:Location {name: 'United States', type: 'country'}),
  (Idaho:Location {name: 'Idaho', type: 'state'}),
  (Lucy:Person {name: 'Lucy'}),
  (Idaho) -[:WITHIN]-> (USA) -[:WITHIN]-> (NAmerica),
  (Lucy) -[:BORN_IN]->(Idaho)
```

This query created 3 locations of different types (vertices) and binds them hierarchically (edges Idaho within USA and USA within NAmerica). Also it creates person vertex and born_in edge.

Example search query:

```cypher
MATCH
  (person) -[:BORN_IN]-> () -[:WITHIN*0..]-> (usa:Location {name: 'USA'}),
  (person) -[:LIVES_IN] -> () -[:WITHIN*0..]-> (eu:Location {name: 'EU'})
RETURN person.name
```

Query literally matches people which were born in any location, wich is within USA and currently lives in any location within EU.

When this will be executed, it won't scan all the people records and find corresponding. Contrariwise, it will probably find `usa` and `eu` locations and go backwards to find people.

`() -[:WITHIN*0..]-> ()` rule means basically follow `WITHIN` edge zero or more times. Like `*` in regular expressions.

In _Cypher_ query we do not specify how do we want data to be queried, but instead what criteria it should match and query optimizer wil decide the best way to execute it.

### Graph Queries in SQL

This may be implemented by Recursive CTE. However this is cumbersome compared to Cypher query.

```sql
WITH RECURSIVE
  within_usa(vertex_id) as (
      SELECT id FROM vertices WHERE vertices.properties->>'name' = 'USA'
    UNION
      SELECT edges.tail_vertex_id
      FROM edges
      JOIN within_usa on edges.head_vertex_id = within_usa.vertex_id
      WHERE edges.label = 'within'
  ),
  within_eu(vertex_id) as (
      SELECT id FROM vertices WHERE vertices.properties->>'name' = 'EU'
    UNION
      SELECT edges.tail_vertex_id
      FROM edges
      JOIN within_eu on edges.head_vertex_id = within_eu.vertex_id
      WHERE edges.label = 'within'
  ),
  born_in_usa as (
    SELECT edges.tail_vertex_id as vertex_id
    FROM edges
    JOIN within_usa on edges.head_vertex_id = within_usa.vertex_id
    WHERE edges.label = 'born_in'
  ),
  lives_in_eu as (
	SELECT edges.tail_vertex_id as vertex_id
	FROM edges
	JOIN within_eu on edges.head_vertex_id = within_eu.vertex_id
	WHERE edges.label = 'lives_in'
  )
SELECT vertices.properties->>'name'
FROM vertices
JOIN born_in_usa on vertices.id = born_in_usa.vertex_id
JOIN lives_in_eu on vertices.id = lives_in_eu.vertex_id;
```

In case of SQL the only declarative part is the last `SELECT`. Inside recursive CTE we imperatively specify how to find each of types of location (going backward through edges).

This represents that appropriate data model is really important. The same query could be written in 4 lines of code (see above Cypher query) if appropriate data model was chosen.

### Triple Stores and SPARQL

Triple graphs are based on triples of (subject, predicate, object). 
For instance, `Jim, likes, bananas`.

In comparison to property graphs, subject is most similar to vertex. Object may be either scalar value (for instance, `Lucy :age 33`, predicate will correspond to property of vertex), or another vertex (for instance `Lucy marriedTo Allan`, predicate will represent graph edge in this case).

Example create query:

```sparql
@prefix: <urn:example:>.
_:lucy a :Person; :name "Lucy"; :bornIn _:idaho.
_:idaho a :Location; :type "state"; :name "Idaho"; :within _:usa.
_:usa a :Location; :type "country"; :name "USA"; :within _:namerica.
_:namerica a :Location; :type "continent"; :name "NAmerica".
```

This syntax with semicolons is semantically identical as we could write `_:lucy a :Person`,  `_:lucy :name "Lucy"`  on separate lines.

##### The semantic web & RDF data model

In early 2000s there was the hype about semantic web and RDF. The idea was that just like websites provide human-readable content, they could also expose machine-readable content in special RDF (resource description framework) format. This would allow to create "web of data" - something like database of everything.

This idea was not implemented and became abandoned.

RDN required URN to be specified. Because, designed for world wide use, there would be conflicts in `lives_in` or `within` meanings for different websites. It used (not necessary resolvable) urls like `<http://my-company.com/namespace#lives_in>`. 

#### SPARQL query language

SPARQL - query language for triple stores using RDF data model.

Example find query:
```sparql
PREFIX : <urn:example:>

SELECT ?personName WHERE {
  ?person :name ?personName.
  ?person :bornIn / :within* / :name "USA".
  ?person :livesIn / :within* / :name "EU".
}
```

This query looks pretty much alike Cypher query.

### The Foundation: Datalog

Datalog provides foundation query languages are build upon.

It defines rules, which can be composed of other rules (just like functions), and requres different kind of thinking.

This is not suitable for one-off queries, but it may be more suitable for complex data.

## Summary

Historically data models starded as one big tree (hierarchical), then relational model was invented to solve issue of many-to-many relationships.  Later NoSQL was invented to handle data which don't fit in relational model well.

NoSQL diverged to:
- Document databases - data comes in self-contained documents, relationships between them are rare. Schema is dynamic;
- Graph databases - data is really complex, has a lot of relations. Anything can be related to everything.

Document and Graph databases don't enforce schema, while relational databases do. 
To enforce application assumptions about schema, there's schema on write approach. It is opposite of schema on read (which is better when we don't know schema beforehand).

Full-text search data models will be covered later.


