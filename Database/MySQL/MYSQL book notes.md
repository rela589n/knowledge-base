## 1. История и архитектура MySQL

### Конкурентный доступ

Для управления конкурентным доступом используется 2 типа блокировок:

- чтения (блокирует запись)
- записи (блокирует и запись и чтение)

Оптимизация: при операциях записи блокировать только часть данных, которые будут затронуты. Так, неконфликтующие операции изменения можно выполнять паралельно.

Табличные блокировки - блокируется полностью таблица.
Построчные блокировки - блокируются конкретные строки. Реализуется в подсистемах хранения (таких как: InnoDB, XtгaDB)

### Транзакции

ACID (atomicity, consistency, isolation, durability):

- Атомарность (полностью или совсем нет)
- Согласованность (бд переходит из одного согласованного состояния в другое)
- Изолированность (результаты не видны пока транзакция не подтверждена)
- Долговечность (при коммите транзакции данные не должны потерятся)

Уровни изолированности:

- `READ UNCOMMITTED` (транзакции могут видеть результаты незавершенных транзакций)
- `READ COMMITTED` (транзакция увидит только подтвержденные результаты другх транзакций, а текущие изменения - невидимы для других транзакций, пока не подтврерждены)
- `REPEATABLE READ` (гарантирует, что операции чтения в пределах одной транзакции дают один и тот же результат; но возможно "фантомное чтение" - при выборке диапазона строк)
- `SERIALIZABLE` (фантомное чтение невозможно, так как транзакции выполняются в таком порядке, чтобы исключить возможность конфликта)


Взаимоблокировка - возникает когда транзакции блокируют те же ресурсы. InnoDB обнаруживает такие циклические зависимости и возвращает ошибку, откатывая транзакцию, которая вызвала блокировку.

Для эффективного коммита транзакции, ведётся журнал транзакций. Вместо обнов­ления таблиц на диске после каждого изменения подсистема хранения данных может изменить находящуюся в памяти копию данных. При этом записав в журнал транзакций мета-информацию. Позже весь результат будет записан на диск (если в этот момент произойдёт ошибка, после перезагрузки можно будет восстановить из журнала).


In MySQL:
Все запросы по-умолчанию работают в режиме `autocommit`, то-есть запрос выполняется в транзакции и сразу-же производится коммит.
Некоторые команды подтверждают транзакцию до её завершения (alter table, lock tables).

Не стоит использовать несколько подсистем хранения в транзакциях, т.к. если одна из них не поддерживает транзакции, то откат будет невозможен.

Не стоит использовать `lock tables` вместе с транзакциями, т.к. последние уже делают построчную блокировку.

### Управление конкурентным доступом

Многие транзакционные движки используют не обычную построчную блокировку, а в сочетании с `MVCC` (multiversion concurrency control).

В InnoDB это работает так:
Для каждой строки дополнительно хранится версия системы когда она была обновлена. Версия увеличивается при каждой транзакции.

- `SELECT` - версия строки должна быть <= версии текущей транзакции (не была обновлена другой транзакцией), поле удаления строки должно быть неопределено (существовала до начала транзакции).
- `INSERT` - записать текущий номер системы вместе со строкой
- `DELETE` - записать текущий номер системы в поле удаления
- `UPDATE` - записать *новую* копию строки используя текущий номер системы, а также записать номер системы как *поле удаления* для прошлой строки.

> MVCC работает только с `READ COMMITTED` и `REPEATABLE READ`.

### Подсистемы хранения

Посмотреть информацию про статус таблицы:

```sql
show table status like 'users' \G
```

#### InnoDB

Хранит данные в tablespaces.

Реализует все уровни изолированности. По-умолчанию, установлен `REPEATABLE READ`.

Использует "кластеризованные индексы".
При многом количестве непервичных индексов, стоит сделать первичный максимально небольшим (все его столбцы содержатся в непервичных).
Поддерживает горячее онлайновое резервное копирование.
Кросплатформенная.

#### MyISAM

Не поддерживает транзакций или построчных блокировок.
Можно блокировать таблицы только полностью.
Можно создать индекс по первым 500 символам столбцов `BLOB` и `TEXT`.
Есть функция отложенной записи ключей.
Поддерживает сжатие таблиц, которые никогда не изменяются.
Геопространственный поиск.

#### Другие

##### Archive

Оптимизирован под большое количество вставок. Сохраняется в сжатом виде. `SELECT` только по таблице целиком.

##### Blackhole

Не сохраняет данные вообще. Полезна для настройки репликаций.

##### CSV

Файлы csv (comma separated values) обрабатываются как таблицы. Полезно для обмена данными.

##### Federated

Проксирует запросы к другому серверу.

##### Memory

Сохраняет данные только в оперативной памяти.
Строки только фиксированной длины.

##### OLTP-подсистемы

###### XtraDB

Эдакая модифицированная версия InnoDB. 
Увеличена производительность, масштабируемость и гибкость. 
Совместима с  InnoDB.

###### PBXT

Похожа на InnoDB.
Репликация на уровне подсистемы. Эффективно управляет большими значениями типа BLOB.

###### TokuDB

Фрактальные индексы.
Используется для хранения больших данных.

##### Ориентированные на столбцы

Infobright, LucidDB, MonetDB, InfiniDB


#### Выбор подсистемы хранения


> Следует использовать InnoDB если нет конкретной необходимости использовать другую.

> Лучше не комбинировать подсистемы хранение без острой необходимости.

Для полнотекстового поиска, можно использовать InnoDB + Sphinx

Выбор по критериях:

- Транзакции. InnoDB or XtraDB.
- Резервное копирование. Если нужно без остановки сервера - InnoDB.
- Восстановление после сбоя. InnoDB.
- Специальные возможности и оптимизациию


##### Журналирование

Подсистемы хранения MyISAM и Archive будут быстро работать для записи, но будут задержки при чтении.

Можно использовать репликацию, так как большое количество запросов записи будет идти в основную таблицу, а чтения - в реплицированную.

Либо, создвать таблицы типа `web_logs_2020_01`.

##### Большие объемы данных

Вполне осуществимо работать с 3-5 Тбайт с подсистемой InnoDB.

При больших объемах можно использовать Infogrighgt или TokuDB.

#### Преобразования таблиц

##### ALTER TABLE

`ALTER TABLE mytaЫe ENGINE = InnoDB;`

Этот способ занимает слишком много времени, поскольку построчно выполняет действие. При этом, таблица полностью заблокирована.

При конвертации и последующей обратной конвертации теряются все присущие старой системе возможности.
(InnoDB -> MyISAM -> InnoDB потеряет все внешиние ключи)

##### Экспорт и импорт

##### Create & Select 

Компромисс между скоростью `ALTER TABLE` и надёжностью `Экспорт и импорт`.


```sql
CREATE TABLE innodb_table LIKE myisam_table;
ALTER TABLE innodb_table ENGINE=InnoDВ;
INSERT INTO innodb_table SELECT * FROМ myisam_table;
```

При больших объемах данных стоит заполнять таблицу частями, используя транзакции.

Перед заполнением нужно блокировать исходную таблицу, чтобы не получить несогласованные данные.

## 2. Эталонное тестирование

Это создание рабочей нагрузки, для того, чтобы подвергнуть систему стрессу.

### Стратегии

- тестировать всё приложение
- тестировать только mysql

Тестирование mysql:

- сравнить различные запросы и схемы;
- протестировать конкретную проблему;

Показатели:

- пропускная способность - кол-во транзакций в единицу времени. www.tpc.org
- время отклика и задержки - общее время выполнения задачи. В процентилях - елси время отклика 5 мс. с 95-м, то в 95% случев задача будет выполнена за 5мс. или быстрее.
- параллелизм (конкурентный доступ) - кол-во одновременных запросов
- масштабируемость - идеальная система должна быть в 2 раза производительней при удвоении ресурсов.

Ошибки эталонного тестирования:

- использование меньшего объема данных, чем требует приложение (с учётом роста);
- неправильное распределение данных;
- нереалистично распределённые параметры;
- однопользовательский сценарий для многопользовательского приложения;
- тестирование распределённого приложения на единичном сервере;
- несоответствие реальному поведению пользователя
- выполнение идентичных запросов в цикле - неидентичные запросы могут сбрасывать кеш;
- отсутствие контроля за ошибками;
- отсутствие тестирования разогрева сервера или отсутствие прогрева перед тестированием;
- использование установок сервера по умолчанию;
- слишком малое время тестирования;

#### Проектирование

Стоит посмотреть, существуют ли уже готовые тесты для вашего случая.
Свои тесты писать сложно, и делать это нужно тчательно спланировав все действия.

#### Длительность

Эталонное тестирование должно выполнятся до тех пор, пока система не будет выглядеть устойчивой. В большинстве случаев, это - несколько или несколько десятков часов.

#### Фиксация результатов

Фиксировать нужно именно необработанные данные. Потому что если будет найдена аномалия, то мы скорее всего захотим больше данных (именно _необработанных_).

Для сохранения результатов, стоит разбивать на несколько файлов по дате.

#### Получение точных результатов

Повторные тесты должны иметь такое же окружение, как и предыдущие. Лучше даже перезагрузить сервер. Изменение нескольких параметров тестирования может сильно повлиять на результат.

При получении странных результатов, не стоит публиковать результаты тестирования, лучше постаратся разобраться почему так произошло.

#### Прогон тестов и анализ результатов

Запуск теста лучше автоматизировать с помощью какого-либо скрипта (к примеру, PHP).

Если нужно быть уверенным в результатах тестирования, стоит прогнать тест несколько раз.

Для анализа результатов также стоит написать скрипты - для воспроизводимости и документирования.

Обязательно нужно построить графики, чтобы проанализировать как ведёт себя система на протяжении времени. В linux есть утилита `gnuplot`.

К примеру, могут быть периодические просадки из-за бллокировки кеша, и тут без графика не обойтись, т.к. среднее значение этого не покажет.

### Инструменты эталонного тестирования

Полностековые инструменты:

1. `ab` - тестирует какое количество запросов в секунду способен выполнить сервер по заданному `url`.
2. `http_load` - более гибкий, нежели `ab`. Можно делать запросы к разным url, которые выбираются случайным способом.
3. `JMeter` - самый гибкий и самый сложный инструмент. Есть GUI, поддерживающий построение графиков. Можно тестировать БД через JDBC, веб-сервера через Http(s), и многое другое. (http://jakarta.apache.org/jmeter/)

Покомпонентные инструменты:

1. `mysqlslap` - иммитирует нагрузку, выдает данные хронометража.
2. `sql-bench` - однопоточный, измеряет скорость выполнения запросов. Полезен для тестирования общей производительности двух серверов. Но не очень точный.
3. `super smack` - работает также с Postgres. Довольно сложный и мощный.
4. `database test suite`
5. `Pecona TPCC-MySQL Tool`
6. `sysbench` - один из самых функциональных

Для тестирования скорости процедур и функций в MySQL есть функция `BENCHMARK`. Для проверки параметризированных функций, стоит параметры записывать в переменные, чтобы не было обращений к кешу.

### Примеры эталонного тестирования

Иммитация 20 пользователей, которые 10 секунд ломятся с максимальной скоростью по адресам, заданным в файле:

#### http_load:

```bash
http_load -rate 20 -seconds 10 urls.txt
```

#### sql-bench:

```bash
cd /usr/share/mysql/sql-bench/
./run-all-tests --server=mysql --user=root --log --fast
```

#### sysbench:

Processor test:

```bash
sysbench --test=cpu --cpu-max-prime=20000 run
```

Test disk (the way innodb works):

```bash
# create data for testing
sysbench --test=fileio --file-total-size=1G prepare

# run test for random read and write
sysbench --test=fileio --file-total-size=1G --file-test-mode=rndrw --max-time=60 --max-requests=0 run

# cleanup
sysbench --test=fileio --file-total-size=1G cleanup
```

Quick OLTP tests...
Memory teting
Threads planner
Mutex


#### dbt2:

Эмулирует нагрузку сложной оперативной обработки транзакций.

#### tpcc-mysql

Более гибкая утилита, нежели dbt2.
Показывает соответствие нормам

```bash
./tpcc_load localhost tpccS username p4ssword 5
./tpcc_start localhost tpccS username p4ssword 5 5 30 30
```


## Профилирование

Производительность - время, необходимое для выполнения задачи, то-есть время отклика системы.

Оптимизация может увеличивать потребление ресурсов, т.к. она направлена на сокращение времени отклика для данной рабочей нагрузки.

Увеличение пропускной способности - побочный эффект оптимизации.

> Нельзя оптимизировать то, что нельзя измерить.

### Оптимизация с помощью профилирования

106...151


# Оптимизация схемы

## Выбор правильных типов данных

1. *Меньше обычно лучше*. Чем меньше тип данных, тем меньше обычно времени уходит на обработку данных. Стоит выбирать минимально возможный для правильного хранения тип данных.
2. *Просто - значит хорошо*. Чем проще тип даных, тем быстрее он может быть обработан. Сравнение строк - намного более тяжёлая операция, нежели чисел. Когда есть встроенный в базу данных тип, то стоит использовать его. Но к примеру, если для ip-адреса нету типа, то можно использовать целые числа.
3. *Без NULL лучше*. Не стоит делать поле _nullable_, если этого делать не стоит (не нужно приложению). Для хранения таких столбцов для каждой строки нужна доп. память, а при использовании индексов, выборка nullable немного медленней, нежели non-nullable.

### Целые числа

tinyint, smallint, mediumint, int, bigint
8        16        24         32   64

int(11) - не определяет размер хранения, а только формат вывода в интерактивном режиме.

### Вещественные числа

Float, Double, Decimal

В _Decimal_ можно хранить не только дробные числа, но также те, которые не помещаются в _biging_.

Decimal используется для хранения точных дробных чисел.
Float & Double дают возможность более быстро делать вычисления, но здесь возможны погрешности.

Для Decimal можно задать нужное количество цифр до и после запятой. Он будет храниться в двоичном виде (9 цифр занимают 4 байта).
Ограничение Decimal - 65 цифр.
Пример: Decimal(18, 9) - суммарно 18 знаков, 9 из которых идут после запятой (остальные 9 - до). Суммарно пример будет занимать 9 байт (по 4 слева и справа и 1 на запятую).


Можно (и стоит) использовать целые числа (кратные наименьшей доле валюты) для хранения денежных значений.


### Строковые типы

Varchar & Char

Varchar - строки переменной длины. На диске храняться только нужные данные. Для хранения длины строки используется 1 или 2 байта. Для строк не длиннее 255 и 65535 соответственно.
Хорошо подходит для данных когда максимальная длина строки гораздо больше средней а также для значений в кодировке UTF-8 когда разные символы могут быть представлены разным количеством байт.

Char - строки фиксированной длины. Хорошо подходит когда данные имеют приблизительно одинаковую длину (например, md5(email)). Приемуществом над varchar может быть то, что такие строки не подвержены фрагментации. Это полезно когда данные часто меняются.


VarBinary & Binary
Используются для хранения двоичных строк (хранятся в виде байтов). Соответственно все сравнения идут как сравнения байтов.

> Можно использовать для хранения различных статусов (или же enum, если не будет проблем с update table)


Blob & Text
Для больших двоичных и символьных данных.

TinyText, SmallText, Text, MediumText, LongText
TinyBlob, SmallBlob, Blob, MediumBlob, LongBlob

Blob == SmallBlob
Text == SmallText


Сортировка данных такого типа ведётся только по первым max_sort_length байтам

> Если можно обойтись без Text|Blob, то лучше так и сделать, поскольку операции с данными данных типов затратны.

> В случае сортировок, то стоит использовать `substring`.

##### Использование Enum вместо строк

При использовании Enum на самом деле значения будут сохраняться в числовом виде, что даст возможность быстро делать выборку. Но при этом, мы не сможем нормально сортировать по полю типа enum.

Конкатенация Enum и строковых данных происходит медленней, нежели просто строковых.


#### Типы DateTime & Time

DateTime
Использует 8 байт для хранения значения. Может хранить любую дату от 1001 до 9999 года с точностью до 1 секунды.

Timestamp
Использует 4 байта для хранения значения. (postgres использует 8)
Хранит кол-во секунд с 1 янв. 1970. Закончится в 2038 году.

Если храним данные разных временных поясов, то поведение timestamp и datetime будет отличаться. При сохранении timestamp, будет сохранено значение gmt. То-есть переданное значение конвертируется, тогда как datetime сохраняется без изменений.

timestamp по умолчанию not nullable, при вставке значения если явно не задан timestamp, будет использовано текущее значение даты. При обновлении аналогично.


#### Битовые типы данных

Технически, все они - строковые типы.

##### Bit - для хранения одного или нескольких значений True/False

Bit(1) - 1 bit
Bit(2) - 2 bits

Максимальная длина - 64.

При извлечении мы получаем бинарною строку. То есть там 0,1 а не символы '0' и '1'.

Если извлекать значение в числовом виде, то получим число, преобразованное из двоичной системы.

При извлечении же строки, может получиться символ ascii, который соответствует этому числу.

Таким образом, по возможности стоит избегать использования этого типа. Как вариант CHAR(0), который может хранить NULL/пустую строку.

##### Set - хранит множество значений, упаковывая их в битовый вектор

##### Использование битовых операций над целыми числами


#### Выбор идентификаторов

Стоит учитывать где этот идентификатор будет использоваться ещё помимо данной таблицы. Например, FK.

Следует брать минимально вместимый тип, которого хватит для хранения всех значений.

- Целые типы (работают быстро, допускают auto_increment)
- Enum и Set (могут быть полезны для статических таблиц определений, но в целом стоит избегать этих типов как PK)
- Строки - следует их избегать, поскольку они сильно замедляют работу и занимают много места.
Когда мы используем случайные значения, то для вставки нужно будет поместить строку в случайное место в индексах, что создает произвольное чтение на диске.


> Для использования uuid можно преобразовать строку в 16-байтное число (с помощью unhex()) и сохранить в binary(16). Значения uuid в некоторой степени последовательны, но всё же это не то самое, что монотонные числа.


> При использовании автоматически сгенерированных схем, стоит их тчательно проверять, не приносят ли они проблем с производительностью. Зачатсую, такие инструменты не позволяют использовать сильные стороны того или иного хранилища.


#### Специальные типы данных


Для хранения ip, стоит использовать unsigned int. Для преобразования в строку и обратно можно использовать функции INEТ_ATON() и INEТ_NTOA()


### Подводные камни проектирования mysql

- слишком много столбцов
Строки копируются от сервера к подсистеме хранения. Хранение больших строк - это затратно, потому что схема отличается от столбцов (если используем VARCHAR)

- слишком много соединений (к примеру, шаблон eav очень плохо ложиться на MYSQL)
Для каждого соединения есть ограничение на 61 таблицу.

- чрезмерное использование enum
Иногда в enum храниться слишком много значений, которые по хорошему должны быть внешними ключами.

- замаскированные enum
enum позволяет хранить лишь одно значение из перечисления, в то время как set даёт возможность хранить несколько значений.

- null
по возможности стоит его избегать, но если нет такой возможности, то лучше использовать null вместо магической константы.

### Нормализация и денормализация

В нормализированной бд каждый факт предоставлен только один раз.

#### Достоинства и недостатки нормализированной схемы

Каждый факт предоставлен один и только один раз.

Достоинства:
- обновление происходит быстрее
- проще изменять данные
- эффективнее по размеру
- проще некоторые запросы чтения

Недостатки:
Нестандартные запросы требуют соединений, а это затратно, т.к. мы не можем использовать единственный индекс.

#### Достоинства и недостатки денормализированной схемы

Запросы не требуют соединений, в итоге выполняются быстрее.
Сложнее обновлять информацию

#### Сочетание нормализации и денормализации

Для выбора правильной схемы данных нужно посмотреть как часто будут обновляться данные, как часто будет производиться их чтение.

Мы можем строить схему исходя из нормализированной и добавлять дубликаты столбцов (как эдакий кеш) чисто для чтения в другие таблицы. Но обновление будет более дорогим. Хотя, в тяжёлом случае можно сделать триггер для обновления, что обновить данные во всех дублированных местах.


Когда мы сортируем по полю из соединённой таблицы, то это будет очень затратно. Для решения этого можно также продублировать данные в дочерней таблице и добавить индекс.

### Кешированные и сводные таблицы

Сводная таблица - хранит промежуточные результаты GROUP BY.
Кешированная таблица - хранит избыточные данные (для которых не страшно устаревание) для чтения.










